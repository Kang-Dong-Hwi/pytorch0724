{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ypAkvi_flku",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3c4db718-b8f4-4161-c2d8-870bd310f870"
      },
      "source": [
        "\n",
        "import torch\n",
        "import os\n",
        "import random\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "import librosa\n",
        "import librosa.display\n",
        "import numba.decorators\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from numba.decorators import jit as optional_jit\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "\n",
        "#PATH = 'C://Projects//keras_talk//keras//intern//dataset//'\n",
        "PATH = '/content/gdrive/My Drive/dataset/'\n",
        "\n",
        "\n",
        "BATCH_SIZE = 40\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zX-Kb0M1jsfa",
        "colab_type": "text"
      },
      "source": [
        "#\n",
        "###### y_data \n",
        "class를\n",
        "\n",
        "0 ~ 180 까지는 20으로 나눠주어서 [0~9]로\n",
        "\n",
        "-1(음성이 없는경우)는 10으로 구성하였습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poVvlwCCfrDO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Y_DATA(y_data):\n",
        "    for idx in range(y_data.shape[0]):\n",
        "        y = y_data[idx]\n",
        "        if y < 0:  y_data[idx] = 10\n",
        "        else:      y_data[idx] = (y//20)\n",
        "    return y_data"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcUKbGfnftls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "dataset_dict = { 0 : 'S_left',        1 : 'S_left_phase',\n",
        "                 2 : 'S_right',       3 : 'S_right_phase',\n",
        "                 4 : 'clean_left',    5 : 'clean_left_phase',\n",
        "                 6 : 'clean_right',   7 : 'clean_right_phase',\n",
        "                 8 : 'idx_drone_end', 9 : 'idx_voice_end',\n",
        "                10 : 'idx_voice_start'}\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEzzcs_fkW0y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_data =  np.load(PATH + 'angle.npy') \n",
        "\n",
        "x_data_list = [0,2,1,3]\n",
        "numpy_dict = dict()\n",
        "\n",
        "for n in x_data_list:\n",
        "    numpy_name    = dataset_dict[n]\n",
        "    numpy_dict[n] = np.load( PATH + numpy_name + '.npy' )\n",
        "\n",
        "\n",
        "# .shape = (257, 382, 1000)\n",
        "S_L_mag = numpy_dict[0]\n",
        "S_L_phase = numpy_dict[1]\n",
        "S_R_mag = numpy_dict[2]\n",
        "S_R_phase = numpy_dict[3]\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kgQuhMMjzg6",
        "colab_type": "text"
      },
      "source": [
        "# \n",
        "\n",
        "##### x_data 전처리\n",
        "\n",
        "1) x_data list 초기화\n",
        "\n",
        "2) (for) total data 개수인 1000번동안\n",
        "\n",
        "    -left, right mag의 idx 번째 array(257,382) 불러오기\n",
        "    -magnitude log 변환\n",
        "    -left, right phase의 idx 번째 array(257,382) 불러오기\n",
        "\n",
        "    -초기화된 list인 x_element에 삽입 (4,257,382)\n",
        "    - x_element의 원소들 정규화\n",
        "\n",
        "    - x_element의 type을 numpy array로 변환 후 x_data에 삽입\n",
        "\n",
        "3) type(x_data)을 numpy array로 변환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1Ogsib5kZNT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "52dd1e1e-c3af-467e-d352-f5bb63395fb2"
      },
      "source": [
        "\n",
        "# x_data 초기화\n",
        "x_data = []\n",
        "\n",
        "\n",
        "'''    x_data,       y_data '''\n",
        "'''(1000,4,257,382), (1000,)'''\n",
        "\n",
        "\n",
        "for idx in range(1000):\n",
        "    \n",
        "    # list 초기화\n",
        "    x_element = []\n",
        "\n",
        "\n",
        "    \"\"\" Mag \"\"\"\n",
        "    # S_left,  S_right 의 idx번째 array\n",
        "    x_L = S_L_mag[:,:,idx]\n",
        "    x_R = S_R_mag[:,:,idx]\n",
        "\n",
        "    \"\"\"log scale [dB]\"\"\"\n",
        "    x_L = 20*np.log10( np.abs(x_L) + np.finfo(np.float16).eps )\n",
        "    x_R = 20*np.log10( np.abs(x_R) + np.finfo(np.float16).eps )\n",
        "    #x_L = librosa.amplitude_to_db(x_L)\n",
        "    #x_R = librosa.amplitude_to_db(x_R)\n",
        "    \n",
        "\n",
        "\n",
        "    \"\"\"phase\"\"\"\n",
        "    # S_left_phase,  S_right_phase 의 idx번째 array\n",
        "    x_L_phase = S_L_phase[:,:,idx]\n",
        "    x_R_phase = S_R_phase[:,:,idx]\n",
        "\n",
        "\n",
        "\n",
        " #   \"\"\"even mode, odd mode\"\"\" \n",
        " #   x_even = (x_L + x_R)/2\n",
        " #   x_odd  = (x_L - x_R)/2\n",
        " #   x_element.append(x_even)\n",
        " #   x_element.append(x_odd)\n",
        "    \n",
        "    \n",
        "    \"\"\"x_element.shape ==> (4, 257, 382)\"\"\"\n",
        "    # 초기화된 list( x_element )에 \n",
        "    # left, right의 mag[dB], phase[rad] 총 4개의 array 삽입 \n",
        "    x_element.append(x_L)\n",
        "    x_element.append(x_R)\n",
        "    x_element.append(x_L_phase)\n",
        "    x_element.append(x_R_phase)\n",
        "\n",
        "\n",
        "\n",
        "    \"\"\"normalization\"\"\"\n",
        "    for k in range(len(x_element)):\n",
        "        x_mean = x_element[k].mean()\n",
        "        x_stdv = x_element[k].std()\n",
        "        x_element[k] = ( (x_element[k] - x_mean ) / x_stdv)\n",
        "    \n",
        "\n",
        "    # x_element 의 type을 list에서 numpy array로 변환후 \n",
        "    #x_data list에 삽입\n",
        "    x_data.append( np.asarray(x_element) )\n",
        "\n",
        "\n",
        "\n",
        "# x_data의 type을 list에서 numpy array로 변환\n",
        "x_data = np.asarray(x_data)\n",
        "\n",
        "# 0,20,40,60...180,-1 인 y_data를  Y_DATA 함수로 \n",
        "# 0,1,2,....,9,10 으로 변환\n",
        "y_data = Y_DATA( y_data )\n",
        "\n",
        "print('done...')\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_wc9q34kkw5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "train_size = 800\n",
        "valid_size = 200\n",
        "\n",
        "\n",
        "x_data = torch.from_numpy( x_data ).float().to('cuda')\n",
        "y_data = torch.from_numpy( y_data ).long().to('cuda')\n",
        "\n",
        "full_dataset = TensorDataset( x_data, y_data )\n",
        "\n",
        "# 8:2 비율로 랜덤\n",
        "train_dataset, valid_dataset = torch.utils.data.random_split( full_dataset, [train_size, valid_size])\n",
        "train_dataset = DataLoader( dataset=train_dataset, batch_size = BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "valid_dataset = DataLoader( dataset=valid_dataset, batch_size = BATCH_SIZE, shuffle=True, drop_last=True)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SftZQbAU7TaW",
        "colab_type": "text"
      },
      "source": [
        "CNN Model은 이전에 MNIST분류에 사용한 model에서\n",
        "\n",
        "convolution layer 한 개를 추가하였습니다.\n",
        "\n",
        "\n",
        "첫번째 convolution layer에서 kernel size는 (7,7) stride가 (2,2)이고\n",
        "\n",
        ", 두번째, 세번째 convolution layer에서 kernel size는 (3,3) stride는 (1,1)입니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlVrlOabknMp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "\n",
        "class CNN (nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        ''' 4 * 257 * 382'''\n",
        "        self.conv1 = nn.Conv2d( in_channels= 4, out_channels= 64, kernel_size = (7,7), stride = (2,2) )\n",
        "        #relu\n",
        "        #pooling\n",
        "        \n",
        "        ''' 64 * 62 * 94'''\n",
        "        self.conv2 = nn.Conv2d( in_channels= 64, out_channels= 64, kernel_size = (3,3) )\n",
        "        #relu\n",
        "        #pooling\n",
        "\n",
        "\n",
        "        ''' 64 * 30 * 46'''\n",
        "        self.conv3 = nn.Conv2d( in_channels= 64, out_channels= 32, kernel_size = (3,3) )\n",
        "        #relu\n",
        "        #pooling\n",
        "\n",
        "\n",
        "        ''' 32 * 14 * 22'''\n",
        "        #flatten\n",
        "\n",
        "        self.lay1  = nn.Linear( 32*14*22, 256)\n",
        "        self.lay2  = nn.Linear( 256, 256 )\n",
        "        self.lay3  = nn.Linear( 256, 64 )\n",
        "        self.lay4  = nn.Linear( 64 , 11 )\n",
        "        \n",
        "        \n",
        "        \n",
        "    def forward(self, output):\n",
        "        output = F.max_pool2d( F.relu( self.conv1(output) ),2 )\n",
        "        output = F.max_pool2d( F.relu( self.conv2(output) ),2 )\n",
        "        output = F.max_pool2d( F.relu( self.conv3(output) ),2 )\n",
        "        \n",
        "        output = output.view(-1, 32*14*22)\n",
        "        \n",
        "        output = F.relu( self.lay1(output) )\n",
        "        output = F.dropout(output, training=self.training)\n",
        "        output = F.relu( self.lay2(output) )\n",
        "        output = F.dropout(output, training=self.training)\n",
        "        output = F.relu( self.lay3(output) )\n",
        "        output = F.dropout(output, training=self.training)\n",
        "        output = F.log_softmax(self.lay4(output), dim=1)\n",
        "        \n",
        "        return output\n",
        "    "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEcOmj4ykvrQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "outputId": "8922bfe4-0349-47ff-bced-9fb05147272d"
      },
      "source": [
        "\n",
        "model = CNN().to('cuda')\n",
        "model\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv1): Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2))\n",
              "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (lay1): Linear(in_features=9856, out_features=256, bias=True)\n",
              "  (lay2): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (lay3): Linear(in_features=256, out_features=64, bias=True)\n",
              "  (lay4): Linear(in_features=64, out_features=11, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9V2tAvAwPl7B",
        "colab_type": "text"
      },
      "source": [
        "###### Model 학습\n",
        "\n",
        "epoch 50, batch size 40\n",
        "\n",
        "optimizer\n",
        "\n",
        "    - Adagrad\n",
        "    - Adam\n",
        "    - SGD\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2R6YSJnkqsd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5b033aa3-55f4-478a-b7eb-3541bc72c006"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "torch.manual_seed(1)\n",
        "criterion = nn.CrossEntropyLoss().to('cuda')\n",
        "\n",
        "\n",
        "\n",
        "'''optimizer'''\n",
        "\n",
        "#optimizer = torch.optim.Adagrad(model.parameters(), lr=0.00001, weight_decay=0.9)\n",
        "#TITLE = 'Adagrad'\n",
        "\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
        "#TITLE = 'Adam'\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.00001, weight_decay=0.9)\n",
        "TITLE = 'SGD'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "EPOCHS = 50\n",
        "train_loss = []\n",
        "train_acc  = []\n",
        "\n",
        "\n",
        "model.train()\n",
        "for epoch in range(EPOCHS):\n",
        "    print('epoch' + str(epoch+1))\n",
        "    total_loss = 0.0\n",
        "    total_acc = 0\n",
        "    \n",
        "    \n",
        "    for i, (data, label) in enumerate(train_dataset):\n",
        "        (data, label) = (data.to('cuda'), label.to('cuda'))\n",
        "\n",
        "        #zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        \n",
        "        # forward + backward = optimize\n",
        "        loss = F.nll_loss(output, label.reshape(BATCH_SIZE))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "\n",
        "        # batch 정확도\n",
        "        preds = output.data.max(1)[1]\n",
        "        corr  = (preds==label.reshape(BATCH_SIZE)).sum().item()\n",
        "        acc   = corr/BATCH_SIZE*100\n",
        "\n",
        "        \n",
        "        # epoch 손실도, 정확도\n",
        "        total_loss += loss.item()\n",
        "        total_acc += corr\n",
        "        \n",
        "\n",
        "        # batch 손실도, 정확도 출력, 저장\n",
        "        train_loss.append(loss)\n",
        "        train_acc.append(acc)\n",
        "        if i%5==0: print('\\tLoss: {:.3f}\\tAcc: {:.3f}'.format(loss.item(), acc))\n",
        "\n",
        "    # epoch 손실도, 정확도 출력\n",
        "    print('epoch' + str(epoch+1) + '  >> Loss: {:.3f}\\tAcc: {:.3f}'.format( total_loss, total_acc/800*100 ))\n",
        "    print()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch1\n",
            "\tLoss: 2.396\tAcc: 5.000\n",
            "\tLoss: 2.393\tAcc: 15.000\n",
            "\tLoss: 2.396\tAcc: 17.500\n",
            "\tLoss: 2.395\tAcc: 5.000\n",
            "epoch1  >> Loss: 47.930\tAcc: 10.625\n",
            "\n",
            "epoch2\n",
            "\tLoss: 2.398\tAcc: 5.000\n",
            "\tLoss: 2.395\tAcc: 12.500\n",
            "\tLoss: 2.397\tAcc: 7.500\n",
            "\tLoss: 2.399\tAcc: 15.000\n",
            "epoch2  >> Loss: 47.930\tAcc: 10.625\n",
            "\n",
            "epoch3\n",
            "\tLoss: 2.396\tAcc: 10.000\n",
            "\tLoss: 2.394\tAcc: 10.000\n",
            "\tLoss: 2.396\tAcc: 10.000\n",
            "\tLoss: 2.396\tAcc: 15.000\n",
            "epoch3  >> Loss: 47.931\tAcc: 10.625\n",
            "\n",
            "epoch4\n",
            "\tLoss: 2.395\tAcc: 12.500\n",
            "\tLoss: 2.395\tAcc: 7.500\n",
            "\tLoss: 2.396\tAcc: 12.500\n",
            "\tLoss: 2.397\tAcc: 7.500\n",
            "epoch4  >> Loss: 47.931\tAcc: 10.625\n",
            "\n",
            "epoch5\n",
            "\tLoss: 2.396\tAcc: 7.500\n",
            "\tLoss: 2.392\tAcc: 15.000\n",
            "\tLoss: 2.395\tAcc: 10.000\n",
            "\tLoss: 2.398\tAcc: 15.000\n",
            "epoch5  >> Loss: 47.930\tAcc: 10.625\n",
            "\n",
            "epoch6\n",
            "\tLoss: 2.399\tAcc: 12.500\n",
            "\tLoss: 2.400\tAcc: 0.000\n",
            "\tLoss: 2.397\tAcc: 12.500\n",
            "\tLoss: 2.399\tAcc: 7.500\n",
            "epoch6  >> Loss: 47.930\tAcc: 10.625\n",
            "\n",
            "epoch7\n",
            "\tLoss: 2.396\tAcc: 12.500\n",
            "\tLoss: 2.397\tAcc: 7.500\n",
            "\tLoss: 2.398\tAcc: 15.000\n",
            "\tLoss: 2.394\tAcc: 12.500\n",
            "epoch7  >> Loss: 47.930\tAcc: 10.625\n",
            "\n",
            "epoch8\n",
            "\tLoss: 2.400\tAcc: 2.500\n",
            "\tLoss: 2.395\tAcc: 15.000\n",
            "\tLoss: 2.392\tAcc: 12.500\n",
            "\tLoss: 2.398\tAcc: 5.000\n",
            "epoch8  >> Loss: 47.931\tAcc: 10.625\n",
            "\n",
            "epoch9\n",
            "\tLoss: 2.396\tAcc: 17.500\n",
            "\tLoss: 2.397\tAcc: 10.000\n",
            "\tLoss: 2.396\tAcc: 10.000\n",
            "\tLoss: 2.396\tAcc: 7.500\n",
            "epoch9  >> Loss: 47.928\tAcc: 10.625\n",
            "\n",
            "epoch10\n",
            "\tLoss: 2.397\tAcc: 7.500\n",
            "\tLoss: 2.396\tAcc: 10.000\n",
            "\tLoss: 2.398\tAcc: 5.000\n",
            "\tLoss: 2.395\tAcc: 15.000\n",
            "epoch10  >> Loss: 47.930\tAcc: 10.625\n",
            "\n",
            "epoch11\n",
            "\tLoss: 2.394\tAcc: 10.000\n",
            "\tLoss: 2.394\tAcc: 7.500\n",
            "\tLoss: 2.399\tAcc: 5.000\n",
            "\tLoss: 2.394\tAcc: 25.000\n",
            "epoch11  >> Loss: 47.931\tAcc: 10.625\n",
            "\n",
            "epoch12\n",
            "\tLoss: 2.394\tAcc: 15.000\n",
            "\tLoss: 2.396\tAcc: 12.500\n",
            "\tLoss: 2.399\tAcc: 2.500\n",
            "\tLoss: 2.395\tAcc: 12.500\n",
            "epoch12  >> Loss: 47.929\tAcc: 10.625\n",
            "\n",
            "epoch13\n",
            "\tLoss: 2.399\tAcc: 7.500\n",
            "\tLoss: 2.398\tAcc: 5.000\n",
            "\tLoss: 2.394\tAcc: 17.500\n",
            "\tLoss: 2.396\tAcc: 10.000\n",
            "epoch13  >> Loss: 47.931\tAcc: 10.625\n",
            "\n",
            "epoch14\n",
            "\tLoss: 2.396\tAcc: 10.000\n",
            "\tLoss: 2.400\tAcc: 10.000\n",
            "\tLoss: 2.399\tAcc: 0.000\n",
            "\tLoss: 2.396\tAcc: 7.500\n",
            "epoch14  >> Loss: 47.931\tAcc: 10.625\n",
            "\n",
            "epoch15\n",
            "\tLoss: 2.393\tAcc: 17.500\n",
            "\tLoss: 2.398\tAcc: 2.500\n",
            "\tLoss: 2.397\tAcc: 5.000\n",
            "\tLoss: 2.395\tAcc: 5.000\n",
            "epoch15  >> Loss: 47.930\tAcc: 10.625\n",
            "\n",
            "epoch16\n",
            "\tLoss: 2.399\tAcc: 5.000\n",
            "\tLoss: 2.400\tAcc: 7.500\n",
            "\tLoss: 2.394\tAcc: 15.000\n",
            "\tLoss: 2.398\tAcc: 15.000\n",
            "epoch16  >> Loss: 47.930\tAcc: 10.625\n",
            "\n",
            "epoch17\n",
            "\tLoss: 2.395\tAcc: 7.500\n",
            "\tLoss: 2.397\tAcc: 10.000\n",
            "\tLoss: 2.395\tAcc: 12.500\n",
            "\tLoss: 2.396\tAcc: 10.000\n",
            "epoch17  >> Loss: 47.931\tAcc: 10.625\n",
            "\n",
            "epoch18\n",
            "\tLoss: 2.395\tAcc: 15.000\n",
            "\tLoss: 2.400\tAcc: 2.500\n",
            "\tLoss: 2.394\tAcc: 17.500\n",
            "\tLoss: 2.400\tAcc: 7.500\n",
            "epoch18  >> Loss: 47.931\tAcc: 10.625\n",
            "\n",
            "epoch19\n",
            "\tLoss: 2.396\tAcc: 10.000\n",
            "\tLoss: 2.399\tAcc: 5.000\n",
            "\tLoss: 2.397\tAcc: 12.500\n",
            "\tLoss: 2.395\tAcc: 15.000\n",
            "epoch19  >> Loss: 47.930\tAcc: 10.625\n",
            "\n",
            "epoch20\n",
            "\tLoss: 2.393\tAcc: 15.000\n",
            "\tLoss: 2.398\tAcc: 7.500\n",
            "\tLoss: 2.398\tAcc: 7.500\n",
            "\tLoss: 2.396\tAcc: 10.000\n",
            "epoch20  >> Loss: 47.931\tAcc: 10.625\n",
            "\n",
            "epoch21\n",
            "\tLoss: 2.399\tAcc: 12.500\n",
            "\tLoss: 2.395\tAcc: 10.000\n",
            "\tLoss: 2.390\tAcc: 20.000\n",
            "\tLoss: 2.396\tAcc: 10.000\n",
            "epoch21  >> Loss: 47.930\tAcc: 10.625\n",
            "\n",
            "epoch22\n",
            "\tLoss: 2.399\tAcc: 7.500\n",
            "\tLoss: 2.396\tAcc: 10.000\n",
            "\tLoss: 2.395\tAcc: 15.000\n",
            "\tLoss: 2.395\tAcc: 15.000\n",
            "epoch22  >> Loss: 47.930\tAcc: 10.625\n",
            "\n",
            "epoch23\n",
            "\tLoss: 2.397\tAcc: 12.500\n",
            "\tLoss: 2.397\tAcc: 12.500\n",
            "\tLoss: 2.399\tAcc: 12.500\n",
            "\tLoss: 2.400\tAcc: 10.000\n",
            "epoch23  >> Loss: 47.930\tAcc: 10.625\n",
            "\n",
            "epoch24\n",
            "\tLoss: 2.397\tAcc: 15.000\n",
            "\tLoss: 2.396\tAcc: 5.000\n",
            "\tLoss: 2.395\tAcc: 15.000\n",
            "\tLoss: 2.395\tAcc: 10.000\n",
            "epoch24  >> Loss: 47.931\tAcc: 10.625\n",
            "\n",
            "epoch25\n",
            "\tLoss: 2.396\tAcc: 10.000\n",
            "\tLoss: 2.397\tAcc: 5.000\n",
            "\tLoss: 2.397\tAcc: 15.000\n",
            "\tLoss: 2.398\tAcc: 10.000\n",
            "epoch25  >> Loss: 47.932\tAcc: 10.625\n",
            "\n",
            "epoch26\n",
            "\tLoss: 2.394\tAcc: 7.500\n",
            "\tLoss: 2.393\tAcc: 12.500\n",
            "\tLoss: 2.394\tAcc: 17.500\n",
            "\tLoss: 2.398\tAcc: 10.000\n",
            "epoch26  >> Loss: 47.930\tAcc: 10.625\n",
            "\n",
            "epoch27\n",
            "\tLoss: 2.398\tAcc: 10.000\n",
            "\tLoss: 2.399\tAcc: 2.500\n",
            "\tLoss: 2.398\tAcc: 12.500\n",
            "\tLoss: 2.390\tAcc: 15.000\n",
            "epoch27  >> Loss: 47.930\tAcc: 10.625\n",
            "\n",
            "epoch28\n",
            "\tLoss: 2.397\tAcc: 17.500\n",
            "\tLoss: 2.398\tAcc: 5.000\n",
            "\tLoss: 2.394\tAcc: 17.500\n",
            "\tLoss: 2.395\tAcc: 10.000\n",
            "epoch28  >> Loss: 47.929\tAcc: 10.625\n",
            "\n",
            "epoch29\n",
            "\tLoss: 2.400\tAcc: 7.500\n",
            "\tLoss: 2.394\tAcc: 12.500\n",
            "\tLoss: 2.395\tAcc: 12.500\n",
            "\tLoss: 2.400\tAcc: 2.500\n",
            "epoch29  >> Loss: 47.931\tAcc: 10.625\n",
            "\n",
            "epoch30\n",
            "\tLoss: 2.397\tAcc: 10.000\n",
            "\tLoss: 2.399\tAcc: 15.000\n",
            "\tLoss: 2.398\tAcc: 7.500\n",
            "\tLoss: 2.395\tAcc: 10.000\n",
            "epoch30  >> Loss: 47.930\tAcc: 10.625\n",
            "\n",
            "epoch31\n",
            "\tLoss: 2.397\tAcc: 10.000\n",
            "\tLoss: 2.395\tAcc: 7.500\n",
            "\tLoss: 2.396\tAcc: 15.000\n",
            "\tLoss: 2.398\tAcc: 10.000\n",
            "epoch31  >> Loss: 47.930\tAcc: 10.625\n",
            "\n",
            "epoch32\n",
            "\tLoss: 2.395\tAcc: 10.000\n",
            "\tLoss: 2.395\tAcc: 10.000\n",
            "\tLoss: 2.399\tAcc: 2.500\n",
            "\tLoss: 2.395\tAcc: 17.500\n",
            "epoch32  >> Loss: 47.931\tAcc: 10.625\n",
            "\n",
            "epoch33\n",
            "\tLoss: 2.395\tAcc: 20.000\n",
            "\tLoss: 2.397\tAcc: 15.000\n",
            "\tLoss: 2.398\tAcc: 7.500\n",
            "\tLoss: 2.392\tAcc: 15.000\n",
            "epoch33  >> Loss: 47.930\tAcc: 10.625\n",
            "\n",
            "epoch34\n",
            "\tLoss: 2.395\tAcc: 5.000\n",
            "\tLoss: 2.402\tAcc: 0.000\n",
            "\tLoss: 2.397\tAcc: 10.000\n",
            "\tLoss: 2.395\tAcc: 10.000\n",
            "epoch34  >> Loss: 47.929\tAcc: 10.625\n",
            "\n",
            "epoch35\n",
            "\tLoss: 2.397\tAcc: 12.500\n",
            "\tLoss: 2.395\tAcc: 15.000\n",
            "\tLoss: 2.400\tAcc: 7.500\n",
            "\tLoss: 2.394\tAcc: 7.500\n",
            "epoch35  >> Loss: 47.929\tAcc: 10.625\n",
            "\n",
            "epoch36\n",
            "\tLoss: 2.399\tAcc: 10.000\n",
            "\tLoss: 2.395\tAcc: 7.500\n",
            "\tLoss: 2.394\tAcc: 17.500\n",
            "\tLoss: 2.395\tAcc: 7.500\n",
            "epoch36  >> Loss: 47.931\tAcc: 10.625\n",
            "\n",
            "epoch37\n",
            "\tLoss: 2.400\tAcc: 5.000\n",
            "\tLoss: 2.399\tAcc: 10.000\n",
            "\tLoss: 2.397\tAcc: 15.000\n",
            "\tLoss: 2.397\tAcc: 10.000\n",
            "epoch37  >> Loss: 47.931\tAcc: 10.625\n",
            "\n",
            "epoch38\n",
            "\tLoss: 2.395\tAcc: 12.500\n",
            "\tLoss: 2.402\tAcc: 5.000\n",
            "\tLoss: 2.396\tAcc: 7.500\n",
            "\tLoss: 2.396\tAcc: 10.000\n",
            "epoch38  >> Loss: 47.931\tAcc: 10.625\n",
            "\n",
            "epoch39\n",
            "\tLoss: 2.396\tAcc: 10.000\n",
            "\tLoss: 2.396\tAcc: 15.000\n",
            "\tLoss: 2.397\tAcc: 10.000\n",
            "\tLoss: 2.395\tAcc: 17.500\n",
            "epoch39  >> Loss: 47.930\tAcc: 10.625\n",
            "\n",
            "epoch40\n",
            "\tLoss: 2.395\tAcc: 15.000\n",
            "\tLoss: 2.399\tAcc: 12.500\n",
            "\tLoss: 2.397\tAcc: 10.000\n",
            "\tLoss: 2.397\tAcc: 10.000\n",
            "epoch40  >> Loss: 47.930\tAcc: 10.625\n",
            "\n",
            "epoch41\n",
            "\tLoss: 2.398\tAcc: 12.500\n",
            "\tLoss: 2.397\tAcc: 15.000\n",
            "\tLoss: 2.400\tAcc: 7.500\n",
            "\tLoss: 2.398\tAcc: 10.000\n",
            "epoch41  >> Loss: 47.930\tAcc: 10.625\n",
            "\n",
            "epoch42\n",
            "\tLoss: 2.397\tAcc: 7.500\n",
            "\tLoss: 2.395\tAcc: 12.500\n",
            "\tLoss: 2.396\tAcc: 7.500\n",
            "\tLoss: 2.397\tAcc: 12.500\n",
            "epoch42  >> Loss: 47.930\tAcc: 10.625\n",
            "\n",
            "epoch43\n",
            "\tLoss: 2.398\tAcc: 10.000\n",
            "\tLoss: 2.394\tAcc: 5.000\n",
            "\tLoss: 2.395\tAcc: 12.500\n",
            "\tLoss: 2.396\tAcc: 10.000\n",
            "epoch43  >> Loss: 47.930\tAcc: 10.625\n",
            "\n",
            "epoch44\n",
            "\tLoss: 2.400\tAcc: 7.500\n",
            "\tLoss: 2.395\tAcc: 12.500\n",
            "\tLoss: 2.396\tAcc: 12.500\n",
            "\tLoss: 2.399\tAcc: 12.500\n",
            "epoch44  >> Loss: 47.929\tAcc: 10.625\n",
            "\n",
            "epoch45\n",
            "\tLoss: 2.398\tAcc: 10.000\n",
            "\tLoss: 2.398\tAcc: 2.500\n",
            "\tLoss: 2.398\tAcc: 10.000\n",
            "\tLoss: 2.396\tAcc: 10.000\n",
            "epoch45  >> Loss: 47.931\tAcc: 10.625\n",
            "\n",
            "epoch46\n",
            "\tLoss: 2.399\tAcc: 5.000\n",
            "\tLoss: 2.392\tAcc: 17.500\n",
            "\tLoss: 2.396\tAcc: 15.000\n",
            "\tLoss: 2.398\tAcc: 0.000\n",
            "epoch46  >> Loss: 47.930\tAcc: 10.625\n",
            "\n",
            "epoch47\n",
            "\tLoss: 2.399\tAcc: 7.500\n",
            "\tLoss: 2.398\tAcc: 12.500\n",
            "\tLoss: 2.394\tAcc: 15.000\n",
            "\tLoss: 2.399\tAcc: 10.000\n",
            "epoch47  >> Loss: 47.930\tAcc: 10.625\n",
            "\n",
            "epoch48\n",
            "\tLoss: 2.394\tAcc: 15.000\n",
            "\tLoss: 2.398\tAcc: 5.000\n",
            "\tLoss: 2.398\tAcc: 7.500\n",
            "\tLoss: 2.394\tAcc: 15.000\n",
            "epoch48  >> Loss: 47.931\tAcc: 10.625\n",
            "\n",
            "epoch49\n",
            "\tLoss: 2.397\tAcc: 7.500\n",
            "\tLoss: 2.396\tAcc: 10.000\n",
            "\tLoss: 2.394\tAcc: 17.500\n",
            "\tLoss: 2.394\tAcc: 12.500\n",
            "epoch49  >> Loss: 47.931\tAcc: 10.625\n",
            "\n",
            "epoch50\n",
            "\tLoss: 2.393\tAcc: 17.500\n",
            "\tLoss: 2.399\tAcc: 10.000\n",
            "\tLoss: 2.397\tAcc: 12.500\n",
            "\tLoss: 2.396\tAcc: 7.500\n",
            "epoch50  >> Loss: 47.930\tAcc: 10.625\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnHabBXifQio",
        "colab_type": "text"
      },
      "source": [
        "training loss, training accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkZfK7O-S3mV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "e7ace3c5-0775-49d1-db10-f05c9676fe54"
      },
      "source": [
        "\n",
        "%matplotlib inline\n",
        "fig, loss_ax = plt.subplots()\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(np.asarray(train_loss), 'y')\n",
        "acc_ax.plot( np.asarray(train_acc),  'b')\n",
        "\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "loss_ax.set_ylim([1.5, 3])\n",
        "\n",
        "acc_ax.set_ylabel('accuracy')\n",
        "acc_ax.set_ylim([0, 100])\n",
        "\n",
        "fig.legend(['loss','acc'], loc='upper right')\n",
        "plt.title('optimizer: '+TITLE)\n",
        "plt.savefig(TITLE+'.png')\n",
        "plt.show()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tOZT4JpQMpM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4a37deb0-d9ae-47d5-d0a2-ea7c3e30c91a"
      },
      "source": [
        "model.eval().to('cuda')\n",
        "\n",
        "val_loss = []\n",
        "val_acc = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for data, label in valid_dataset:\n",
        "        output = model(data)\n",
        "        preds  = torch.max(output.data, 1)[1]\n",
        "        total   += len(label)\n",
        "        \n",
        "        label = label.reshape(BATCH_SIZE)\n",
        "        correct += (preds==label).sum().item()\n",
        "\n",
        "\n",
        "        val_loss.append\n",
        "      \n",
        "    print('Test Accuracy: ', 100.*correct/total)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy:  12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZE9zVMLdHnD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}